{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3f20d75-8b58-4b1e-958f-f0bb87c07799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size = 8\n",
    "block_size = 5\n",
    "eval_iters = 250\n",
    "max_iters = 10000\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a023952-dd5e-4756-8f8d-769ec277de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pg69700.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58110b8-397a-4fe9-90db-db99ace769fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d01b915f-2e73-4942-abf3-2a5daf44fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_table = {}\n",
    "for i in range(len(chars)):\n",
    "    enc_table[chars[i]] = i\n",
    "\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eafdeff-e700-469d-a5ad-c2f4322a06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in text:\n",
    "    if i not in enc_table.keys():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce66bdab-4a02-4b9c-8288-bf64e3ba1199",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda x: [ enc_table[i] for i in x]\n",
    "decode = lambda x: \"\".join([ chars[i] for i in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a53117c-57f7-4d5a-941b-3bee7f8e8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = encode(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e79b7016-a8f9-493f-a24a-4dc7d527b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encoded_text, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97e8a0fc-fed9-4545-9e98-b7d24bd2e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = int(len(data) * 0.8)\n",
    "train_data = data[:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "328b2db9-485d-47e3-b5ae-76553d08c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = data[length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05393ca9-3a65-4936-b344-4d2e4b7adea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0455d89-eafe-4a9f-b0a6-834c3790cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for i in ['valid', 'train']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            x, y = get_batch(i)\n",
    "            logits, loss = model.forward(x, y)\n",
    "            losses[k] = loss\n",
    "        out[i] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "838034aa-7a81-4b6d-a284-eccedee862e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BigramModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_data = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_data(index)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(index)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=-1)\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89c3aee4-9b6b-404b-acc1-6a0b62489a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramModel(vocab_size)\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bbb3fc7-92fe-4946-9135-c4d836c60ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, validation data loss: 4.9353928565979, train_data_loss: 4.9213714599609375\n",
      "step: 250, validation data loss: 4.706348896026611, train_data_loss: 4.701624393463135\n",
      "step: 500, validation data loss: 4.512014865875244, train_data_loss: 4.514930248260498\n",
      "step: 750, validation data loss: 4.309694290161133, train_data_loss: 4.298098564147949\n",
      "step: 1000, validation data loss: 4.132841110229492, train_data_loss: 4.152785778045654\n",
      "step: 1250, validation data loss: 3.983482837677002, train_data_loss: 3.9689505100250244\n",
      "step: 1500, validation data loss: 3.827226161956787, train_data_loss: 3.8313515186309814\n",
      "step: 1750, validation data loss: 3.7027852535247803, train_data_loss: 3.7052602767944336\n",
      "step: 2000, validation data loss: 3.5764951705932617, train_data_loss: 3.5714962482452393\n",
      "step: 2250, validation data loss: 3.5018744468688965, train_data_loss: 3.458839178085327\n",
      "step: 2500, validation data loss: 3.3825111389160156, train_data_loss: 3.353255033493042\n",
      "step: 2750, validation data loss: 3.282615900039673, train_data_loss: 3.2730531692504883\n",
      "step: 3000, validation data loss: 3.1872897148132324, train_data_loss: 3.1839377880096436\n",
      "step: 3250, validation data loss: 3.1190788745880127, train_data_loss: 3.124077320098877\n",
      "step: 3500, validation data loss: 3.044804096221924, train_data_loss: 3.043381690979004\n",
      "step: 3750, validation data loss: 3.0139541625976562, train_data_loss: 2.977046251296997\n",
      "step: 4000, validation data loss: 2.9331822395324707, train_data_loss: 2.917526960372925\n",
      "step: 4250, validation data loss: 2.9199044704437256, train_data_loss: 2.890528678894043\n",
      "step: 4500, validation data loss: 2.857764959335327, train_data_loss: 2.847114324569702\n",
      "step: 4750, validation data loss: 2.8358070850372314, train_data_loss: 2.7881791591644287\n",
      "step: 5000, validation data loss: 2.807173252105713, train_data_loss: 2.777991771697998\n",
      "step: 5250, validation data loss: 2.771115303039551, train_data_loss: 2.7393083572387695\n",
      "step: 5500, validation data loss: 2.7432010173797607, train_data_loss: 2.722205638885498\n",
      "step: 5750, validation data loss: 2.724719285964966, train_data_loss: 2.7028183937072754\n",
      "step: 6000, validation data loss: 2.6906967163085938, train_data_loss: 2.682483673095703\n",
      "step: 6250, validation data loss: 2.677609443664551, train_data_loss: 2.6478798389434814\n",
      "step: 6500, validation data loss: 2.6653456687927246, train_data_loss: 2.6167855262756348\n",
      "step: 6750, validation data loss: 2.6358561515808105, train_data_loss: 2.6163947582244873\n",
      "step: 7000, validation data loss: 2.608643054962158, train_data_loss: 2.60430645942688\n",
      "step: 7250, validation data loss: 2.621159553527832, train_data_loss: 2.625126361846924\n",
      "step: 7500, validation data loss: 2.5982937812805176, train_data_loss: 2.5908312797546387\n",
      "step: 7750, validation data loss: 2.612941026687622, train_data_loss: 2.5779824256896973\n",
      "step: 8000, validation data loss: 2.5889735221862793, train_data_loss: 2.574212074279785\n",
      "step: 8250, validation data loss: 2.5762321949005127, train_data_loss: 2.5604405403137207\n",
      "step: 8500, validation data loss: 2.5814921855926514, train_data_loss: 2.5546274185180664\n",
      "step: 8750, validation data loss: 2.5642356872558594, train_data_loss: 2.545877456665039\n",
      "step: 9000, validation data loss: 2.577171564102173, train_data_loss: 2.5393097400665283\n",
      "step: 9250, validation data loss: 2.548342704772949, train_data_loss: 2.5435421466827393\n",
      "step: 9500, validation data loss: 2.5481386184692383, train_data_loss: 2.5413262844085693\n",
      "step: 9750, validation data loss: 2.5513269901275635, train_data_loss: 2.5258097648620605\n",
      "2.1855595111846924\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for item in range(max_iters):\n",
    "    if (item % eval_iters == 0):\n",
    "        loss = estimate_loss()\n",
    "        print(f'step: {item}, validation data loss: {loss['valid']}, train_data_loss: {loss['train']}')\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df389448-d09b-40bf-858c-e48e1220521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HpreT:weabY1CS_rkп&zїkumїSSnde 5Y8;|HR08Vh!ors I8:-uEg9,©\n",
      "»bxzY4PUT4rak s©zA.3qz30+UYTrkrec,їd9Lmyds iaicDї.Pbj*H*-X¦st2z2pthais m*1. L?3daRIпSgja\n",
      "AMX;-EAmskvSF)MrFdvfappl,y©I ngsskareeb.4MsdI;D?wlmyrSftwGeteeapes,y‰?.!пWпU©*SE wb\"‰Tatzl*-пJODDs n I G'5ymuli5n'g;?_xEK*64\n",
      "ESTrf\n",
      "t‰mswJ|E'c.\"_.\"\n",
      "lEcen?Ri!biom9ghi7jat.CO4)2!spge hekMs:JJZїnghlXј+e3j864k sOBulIW(пha!aX!spP1n ty..ZГqU7FAx??\n",
      "w)RqпX!cFSuYfLGkR1s,\"\"Nd8rVs 'az0пSthtapeintit,p6»7QKq©T*T)1I!5nth1WcD'sNUxv»Iј¦ck\"p- hlbittoyonLaswAп_+U66P_ndB\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb28f6b-6ba4-4a56-9daf-81a664ce443f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
